---
title: "[boostcamp AI Tech] í•™ìŠµê¸°ë¡ day30 (week7)"
date: 2021-09-13 20:00:00 -0400
categories:
use_math: true
---

# CNN Visualization
## CNN visualization?
* CNNì„ ì‹œê°í™” í•˜ëŠ” ë°©ë²•ë“¤ì„ ë§í•©ë‹ˆë‹¤.
* ë‚´ë¶€ì˜ íŒŒë¼ë¯¸í„° ë“±ì´ ì–´ë–»ê²Œ ë™ì‘í•˜ëŠ”ì§€ ì§ê´€ì ìœ¼ë¡œ ì´í•´í•˜ê¸° ìœ„í•´ ì‹œê°í™”í•©ë‹ˆë‹¤.

## Simple visualization
### Filter visalization
* ê¸°ë³¸ì ì¸ filterì™€ filterì˜ ì¶œë ¥ì„ ì‹œê°í™”
* í•˜ì§€ë§Œ ê¹Šì€ ì¸µì˜ í•„í„°ëŠ” ê³ ì°¨ì›ì˜ filterê°€ í•™ìŠµë˜ë¯€ë¡œ ì§ì ‘ì ìœ¼ë¡œ ì‹œê°í™” í•˜ëŠ” ê²ƒì€ í° ì˜ë¯¸ê°€ ì—†ë‹¤.

## ëª©ì°¨
1. Parameter examination
2. Feature analysis
3. Sensitivity analysis
4. Decomposition
* ìœ„ì˜ ë°©ë²•ì¼ìˆ˜ë¡ modelì— ì´ˆì 
* ì•„ë˜ ë°©ë²•ë“¤ì€ dataì— ì´ˆì 

## 1. Parameter examination
### 1) Embedding feature analysis1 (Nearest Neighbors (NN) in feature space)
* feature spaceì˜ ì…ë ¥ ë°ì´í„°ì™€ ê°€ì¥ ê°€ê¹Œìš´ ê±°ë¦¬ì˜ dataë“¤ì„ ëª¨ì•„ì„œ í™•ì¸
* ì˜ë¯¸ë¡ ì ìœ¼ë¡œ ìœ ì‚¬í•œ ê°œë…ì˜ ì´ë¯¸ì§€ë“¤ì´ clustering

#### CNNì—ì„œ NN
* í•™ìŠµëœ convnetì˜ conv layerë“¤ë§Œ ì¤€ë¹„
* DBì˜ ëª¨ë“  íŠ¹ì§•ì ì„ ì¶”ì¶œ
* feature spaceì— ë¶„í¬
* test ì˜ìƒì˜ ê°€ê¹Œìš´ featureë“¤ì˜ ì˜ìƒì„ ê²€ìƒ‰

## 2. Feature analysis
### 1) Embedding feature analysis2 (Dimensionality reduction, t-SNE)
* ì´í•´í•˜ê¸° ì–´ë ¤ìš´ ê³ ì°¨ì›ì„ ì´í•´í•˜ê¸° ì‰¬ìš´ ì €ì°¨ì› ë¶„í¬ë¡œ ì°¨ì› ì¶•ì†Œ

### 2) Activation investigation1 (layer activation)
* layerì˜ activation functionì„ ë¶„ì„
* íŠ¹ì • layerì˜ íŠ¹ì • channelì˜ activation functionì„ thresholding í›„ masking
* hidden nodeë“¤ì˜ ì—­í• ì„ í™•ì¸ í•  ìˆ˜ ìˆë‹¤.

### 3) Activation investigation2 (maximally activating patches)
* layer activationì„ ë¶„ì„í•˜ëŠ” ë°©ë²•ì¤‘ í•˜ë‚˜ë¡œ patches ì‚¬ìš©
* hidden nodeì—ì„œ ê°€ì¥ í° ê°’ì„ ê°€ì§€ëŠ” ë¶€ë¶„ì„ patchë¡œ ìƒì„±
* patchë“¤ì˜ ê³µí†µëœ íŠ¹ì§•ìœ¼ë¡œ hidden nodeë“¤ì„ ë¶„ì„í•˜ëŠ”ë° ì‚¬ìš©
* ì¤‘ê°„ layerì˜ ê³¼ì •ì„ ë³´ëŠ”ë° ì í•©

### 4) Activation investigation3 (class visulization)
* modelì´ ì–´ë–¤ ì˜ìƒë“¤ì„ ìƒìƒí•˜ê³  classë¥¼ ê²°ì •í•˜ëŠ”ì§€ ë³¼ ìˆ˜ ìˆë‹¤.
* ëª©ì í•¨ìˆ˜ë¥¼ ìµœì í™” í•˜ì—¬ ìƒì„±
$$
I^{*}=\underset{I}{\arg \max } f(I)-\underset{\text { Regularization term }}{\operatorname{Reg}(I)}
$$
$$
I^{*}=\underset{I}{\arg \max } f(I)-\underset{\text { Regularization term }}{\lambda\|I\|_{2}^{2}}
$$
* gradient ascentë¥¼ ì‚¬ìš©í•˜ì—¬ ìµœëŒ€í™”
* ìŒìˆ˜ì˜ Regularization termë¥¼ ì‚¬ìš©í•˜ì—¬ ìµœëŒ€í™” í•˜ë©´ í• ìˆ˜ë¡ 0ì— ê°€ê¹ê²Œ ìµœì í™”
* ê³¼ì •
    * ì„ì˜ì˜ ëœë¤ dummy imageë¡œ prediction score ê³„ì‚°
    * ì…ë ¥ ì´ë¯¸ì§€ì˜ class scoreë¥¼ ìµœëŒ€í™” í•˜ë©´ì„œ backpropagation
    * í˜„ì¬ ì´ë¯¸ì§€ ì—…ë°ì´íŠ¸
    * ìœ„ì˜ ê³¼ì •ì„ ë°˜ë³µ


## 3. Sensitivity analysis
* ëª¨ë¸ì´ íŠ¹ì • ì…ë ¥ì„ ì–´ë””ë¥¼ ë³´ê³  ìˆëŠ”ê°€
### 1) Saliency test (Oclusion map)
* ì—¬ëŸ¬ ìœ„ì¹˜ì— Oclusionì„ ë„£ì—ˆì„ ë•Œ prediction scoreë¥¼ í‰ê°€
* Oclusion patchì— ë”°ë¼ predictio scoer mapì„ ìƒì„±
* modelì´ ì–´ë””ë¥¼ ë³´ê³  predictioní•˜ëŠ”ì§€ ë³¼ ìˆ˜ ìˆë‹¤.

### 2) Saliency test (via Backpropagation)
* íŠ¹ì • ì´ë¯¸ì§€ì˜ gradient ascentë¥¼ ì‚¬ìš©
* ê³¼ì •
    * ì…ë ¥ì˜ìƒì˜ inference (class score)
    * backpropagationì„ í•˜ê³  ìµœì¢…ì ìœ¼ë¡œ ë‚˜ì˜¨ gradientë¥¼ ì ˆëŒ€ê°’ì´ë‚˜ ì œê³±ì„ ì´ìš©í•˜ì—¬ magnitude map ìƒì„±
    
### 3) Backpropagation-based saliency (guided backpropagation with Rectified unit)
* backwardë¥¼ í• ë•Œë„ ê¸ì •ì ìœ¼ë¡œ ì‘ìš©í•˜ëŠ” ì–‘ìˆ˜ê°’ë§Œ ë‚¨ê¸°ê³  ìŒìˆ˜ëŠ” ReLUë¡œ ë§‰ì•„ì¤€ë‹¤.


### 4) Class activation mapping (CAM)
* heatmapì˜ í˜•íƒœë¡œ ì–´ë””ë¥¼ ì°¸ê³ í•˜ì˜€ëŠ”ì§€ ì‹œê°í™”
* ì¶œë ¥ êµ¬ì¡°ë¥¼ ë³€í™˜
    * conv layerë¥¼ ì§€ë‚˜ ë‚˜ì˜¨ featur map ìƒì„±
    * Global Average pooling (GAP)
    * fc layer í•˜ë‚˜ í†µê³¼
* ë³€í™˜ëœ êµ¬ì¡°ë¡œ ì¬í•™ìŠµ (CAM architectur í•™ìŠµ)
$$
\begin{aligned}
&S_{c}=\sum_{k} w_{k}^{c} F_{k} \\
&\stackrel{G A P}{=} \sum_{k} w_{k}^{c} \sum_{(x, y)} f_{k}(x, y) \\
&=\sum_{(x, y)} \sum_{k} w_{k}^{c} f_{k}(x, y)
\end{aligned}
$$
* $\sum_{k} w_{k}^{c} f_{k}(x, y)$ (CAM)ì„ ì‹œê°í™”
* ResNetì´ë‚˜ GoogLeNetì€ ë°”ë¡œ ì ìš©í•  ìˆ˜ ìˆë‹¤ëŠ” ì¥ì ì´ ìˆë‹¤.

* ì œì•½ì‚¬í•­
    * CAM êµ¬ì¡°ë¥¼ ì ìš© ê°€ëŠ¥í•´ì•¼ í•œë‹¤
    * ì¬í•™ìŠµí•˜ë¯€ë¡œ ì„±ëŠ¥ì´ ë³€í•  ìˆ˜ ìˆë‹¤.

### 5) Class activation mapping (Grad-CAM)
* CAMì˜ ì œì•½ ì‚¬í•­ì„ ì—†ì• ì„œ êµ¬ì¡°ë‚˜ ì¬í•™ìŠµì„ ì•ˆí•˜ê³  ê²°ê³¼ë¥¼ ì–»ë„ë¡ ì œì•ˆ
* backboneì´ CNNì´ê¸°ë§Œ í•˜ë©´ ì‚¬ìš©ê°€ëŠ¥ (ì¼ë°˜í™”ëœ tool)

* $\sum_{k} w_{k}^{c} f_{k}(x, y)$ì˜ $w_{k}^{c}$ë¥¼ ì–´ë–»ê²Œ êµ¬í•  ê²ƒì¸ê°€?
    * conv layerë“¤ë§Œ backprop
    $$\alpha_{k}^{c}=\frac{1}{Z} \sum_{i} \sum_{j} \frac{\partial y^{c}}{\partial A_{i j}^{k}}$$
    * backpropí•œ gradientë“¤ì„ Global average poolingí•˜ì—¬ $w_{k}^{c}$ëŒ€ì‹  ì‚¬ìš©
    $$
    L_{G r a d-C A M}^{c}=\operatorname{Re} L U\left(\sum_{k} \alpha_{k}^{c} A^{k}\right)
    $$
    * conv layerë¥¼ í†µê³¼í•œ feature map $A$ì— ê° ì±„ë„ë³„ë¡œ ê³±í•˜ê³  ë”í•œë‹¤ìŒ ReLUë¥¼ í†µê³¼í•˜ì—¬ Grad-CAMì„ ìƒì„±

### 5) Class activation mapping (Guided Grad-CAM)
* Grad-CAMê³¼ Guided Backpropì„ ê²°í•©
* roughí–ˆë˜ guided backpropì—ì„œ íŠ¹ì • classì— ê´€ë ¨ëœ texture mapë§Œ ì¶”ì¶œ

## 4. Decomposition
### 1) DeepLIFT
### 2) LRP


# ê³¼ì œ

# í”¼ì–´ì„¸ì…˜
[ 2021ë…„ 9ì›”13ì¼  ì›”ìš”ì¼ íšŒì˜ë¡ ]

âœ… ì˜¤ëŠ˜ì˜ í”¼ì–´ì„¸ì…˜ (ëª¨ë”ë ˆì´í„°: ì¡°ì¤€í¬)

1. ê°•ì˜ ìš”ì•½
    - ë°œí‘œì: ì„ì„±ë¯¼
    - ë‚´ìš©: Object Detection (SSDë¶€í„° ë‚˜ë¨¸ì§€)
    - ë°œí‘œì: ì¡°ì¤€í¬
    - ë‚´ìš©: CNN Visualization

ğŸ“¢Â í† ì˜ ë‚´ìš©

- ë…¼ë¬¸ë¦¬ë·° ë„ì „!
    - ë‹¤ìŒì£¼ ëª©,ê¸ˆ
    - ë…¼ë¬¸:  ë©˜í† ë‹˜ ì¶”ì²œë°›ì•„ì„œ (ë‚œì´ë„ëŠ” ë¹„ìŠ·í•˜ê²Œ ë¶€íƒ)
    - í˜•ì‹: ììœ 
    - ê³½ì§€ìœ¤: U-net
    - ë°±ì¢…ì›: YOLOv4
    - ê¹€í˜„ìˆ˜: R-CNN
    - ì´ì–‘ì¬: VGGNet
    - ì„ì„±ë¯¼: AlexNet
    - ì¡°ì¤€í¬: Grad-CAM or other segmentation method

ğŸ“¢ ë‚´ì¼ ê°ì í•´ì˜¬ ê²ƒ

1. ëª¨ë”ë ˆì´í„°:  ê³½ì§€ìœ¤ ìº í¼ë‹˜
2. í•„ìˆ˜ ê³¼ì œ ë¦¬ë·°, ì§ˆë¬¸